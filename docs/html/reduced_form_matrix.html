<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "https://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=9"/>
<meta name="generator" content="Doxygen 1.8.17"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<title>A singular Riemannian geometry approach to Deep Neural Networks.: On the reduced form of the Jacobian matrices</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    extensions: ["tex2jax.js"],
    jax: ["input/TeX","output/HTML-CSS"],
});
</script>
<script type="text/javascript" async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js"></script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr style="height: 56px;">
  <td id="projectalign" style="padding-left: 0.5em;">
   <div id="projectname">A singular Riemannian geometry approach to Deep Neural Networks.
   </div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.8.17 -->
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:cf05388f2679ee054f2beb29a391d25f4e673ac3&amp;dn=gpl-2.0.txt GPL-v2 */
var searchBox = new SearchBox("searchBox", "search",false,'Search');
/* @license-end */
</script>
<script type="text/javascript" src="menudata.js"></script>
<script type="text/javascript" src="menu.js"></script>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:cf05388f2679ee054f2beb29a391d25f4e673ac3&amp;dn=gpl-2.0.txt GPL-v2 */
$(function() {
  initMenu('',true,false,'search.php','Search');
  $(document).ready(function() { init_search(); });
});
/* @license-end */</script>
<div id="main-nav"></div>
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<iframe src="javascript:void(0)" frameborder="0" 
        name="MSearchResults" id="MSearchResults">
</iframe>
</div>

<div id="nav-path" class="navpath">
  <ul>
<li class="navelem"><a class="el" href="index.html">Introduction</a></li>  </ul>
</div>
</div><!-- top -->
<div class="PageDoc"><div class="header">
  <div class="headertitle">
<div class="title">On the reduced form of the Jacobian matrices </div>  </div>
</div><!--header-->
<div class="contents">
<div class="textblock"><p>The Jacobian matrix containing the derivatives with respect the the weights and biases of a fully connected layer is a sparse matrix. For example, let us consider a fully connected layer from \( \mathbb{R}^{2}\) to \( \mathbb{R}^{2} \) with sigmoid activation function. We can write the map realizing the layer, as:</p>
<p>\( \Lambda(\underline{X},\underline{W}_1,b_1,\underline{W}_2,b_2) = \begin{pmatrix} \sigma (\underline{W}_1 \cdot \underline{X} + b_1) \\ \sigma (\underline{W}_2 \cdot \underline{X} + b_2) \end{pmatrix} \)</p>
<p>where \(\underline{W}_1 = (w_{11},w_{12})\) and \(\underline{W}_2 = (w_{21},w_{22})\) are the weights of the layer, \(b_1,b_2\) the biases and \(\underline{X} = (x_1,x_2)\) the input data. Calling \(\Lambda_1(\underline{X},\underline{W}_1,b_1) = \sigma (\underline{W}_1 \cdot \underline{X} + b_1)\) and \(\Lambda_2(\underline{X},\underline{W}_2,b_2) = \sigma (\underline{W}_2 \cdot \underline{X} + b_2)\) the two components of the map \( \Lambda\), the Jacobian matrix containing the derivatives with respect to the weights and the biases, for a fixed input, is given by</p>
<p class="formulaDsp">
\[ J \Lambda = \begin{pmatrix} \frac{\partial \Lambda_1}{\partial w_{11}} &amp; \frac{\partial \Lambda_1}{\partial w_{12}} &amp; \frac{\partial \Lambda_1}{\partial b_1} &amp; \frac{\partial \Lambda_1}{\partial w_{21}} &amp; \frac{\partial \Lambda_1}{\partial w_{22}} &amp; \frac{\partial \Lambda_1}{\partial b_2}\\ \frac{\partial \Lambda_2}{\partial w_{11}} &amp; \frac{\partial \Lambda_2}{\partial w_{12}} &amp; \frac{\partial \Lambda_2}{\partial b_1} &amp; \frac{\partial \Lambda_2}{\partial w_{21}} &amp; \frac{\partial \Lambda_2}{\partial w_{22}} &amp; \frac{\partial \Lambda_2}{\partial b_2} \end{pmatrix} \]
</p>
<p>Considering that \(\Lambda_1\) does not depend on \(w_{21},w_{22},b_2\) and that \(\Lambda_2\) is not a function of \(w_{11},w_{12},b_1\), we find that the Jacobian of \( \Lambda \) assumes the form</p>
<p class="formulaDsp">
\[ J \Lambda = \begin{pmatrix} \frac{\partial \Lambda_1}{\partial w_{11}} &amp; \frac{\partial \Lambda_1}{\partial w_{12}} &amp; \frac{\partial \Lambda_1}{\partial b_1} &amp; 0 &amp; 0 &amp; 0\\ 0 &amp; 0 &amp; 0 &amp; \frac{\partial \Lambda_2}{\partial w_{21}} &amp; \frac{\partial \Lambda_2}{\partial w_{22}} &amp; \frac{\partial \Lambda_2}{\partial b_2} \end{pmatrix} \]
</p>
<p>Now let us consider a generic fully connected layers with n nodes, whose input is a vector space of dimension m. Then, following the , the map realizing the layer seen as a function of the weights and biases, is a vector valued function from \( \mathbb{R}^{n \cdot (m+1)} \) to \( \mathbb{R}^{n} \).The Jacobian matrix of this layer is a \( m \times (n \cdot m)\) matrix with the following structure:</p><ul>
<li>In the first row, only the first \( m+1 \) entries are in general non-null.</li>
<li>In the second row, the first \( m+1 \) entries are null, then the next block of \( m+1 \) elements are non-null. The remainder of this row contains only zeroes.</li>
<li>In the k-th row, the first \( (k-1)*(m+1) \) entries are null, then we find \( m+1 \) non-null entries and finally the rest of the rows is made of zeroes. Therefore, to save space (and computation time) we store only the non-null entries in a \( m \times n\) matrix that we called the reduced form of the Jacobian, or reduced matrix for short.</li>
</ul>
<p>In order to compute the pullback of the metric, however, we need to compute some products between the Jacobian matrices. To this end, we implement the functions reduced_standard_mul and standard_reduced_mul contained in <a class="el" href="matrix__utils_8h_source.html">matrix_utils.h</a>, computing the product between a reduced matrix and a standard one (reduced_standard_mul) and the product bewteen a standard matrix and a reduced one (standard_reduced_mul). The conversion between the standard and the reduced forms of the Jacobian matrix are handled by the reduced_to_standard and standard_to_reduced functions. </p>
</div></div><!-- contents -->
</div><!-- PageDoc -->
<!-- start footer part -->
<hr class="footer"/><address class="footer"><small>
Generated by &#160;<a href="http://www.doxygen.org/index.html">
<img class="footer" src="doxygen.png" alt="doxygen"/>
</a> 1.8.17
</small></address>
</body>
</html>
